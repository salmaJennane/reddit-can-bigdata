"""
========================================================
ğŸ¤– SPARK ML FINAL - SENTIMENT ANALYSIS CAN 2025
========================================================
âœ” Auto-labeling CORRIGÃ‰ (mots-clÃ©s tragiques ajoutÃ©s)
âœ” PondÃ©ration score Reddit amÃ©liorÃ©e
âœ” Emojis + engagement
âœ” Multi-modÃ¨les avec comparaison
âœ” Mapping CORRECT des labels
========================================================
"""

# ===============================
# IMPORTS
# ===============================
from pyspark.sql import SparkSession
from pyspark.sql.functions import (
    col, length, udf, current_timestamp, when,
    regexp_replace
)
from pyspark.sql.types import StringType, IntegerType
from pyspark.ml.feature import (
    Tokenizer, StopWordsRemover, CountVectorizer,
    IDF, StringIndexer, IndexToString, VectorAssembler
)
from pyspark.ml.classification import (
    LogisticRegression, NaiveBayes, RandomForestClassifier
)
from pyspark.ml import Pipeline
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
from pymongo import MongoClient
import builtins
import re

# ===============================
# SPARK SESSION
# ===============================
print("=" * 70)
print("ğŸ¤– SPARK ML FINAL - SENTIMENT ANALYSIS CAN 2025")
print("=" * 70)

spark = SparkSession.builder \
    .appName("RedditSentimentMLFinal") \
    .config("spark.driver.memory", "2g") \
    .getOrCreate()

spark.sparkContext.setLogLevel("WARN")
print("âœ… Spark Session crÃ©Ã©e!")

# ===============================
# MONGODB
# ===============================
print("\nğŸ”Œ Connexion Ã  MongoDB...")
mongo = MongoClient("mongodb://admin:admin123@mongodb:27017/")
db = mongo["reddit_can"]
posts_col = db["processed_posts"]
results_col = db["sentiment_results"]
print("âœ… MongoDB connectÃ©!")

# ===============================
# LOAD DATA
# ===============================
print("\nğŸ“¥ Chargement des donnÃ©es depuis MongoDB...")
docs = list(posts_col.find({}, {"_id": 0}))

if not docs:
    print("âŒ Aucune donnÃ©e trouvÃ©e")
    exit(1)

df = spark.createDataFrame(docs)
print(f"âœ… DataFrame Spark prÃªt : {df.count()} lignes")

df = df.select("id", "combined_text", "score", "num_comments")
df = df.filter(length(col("combined_text")) > 20)

print(f"ğŸ“Š AprÃ¨s filtrage : {df.count()} lignes")

# ===============================
# EMOJIS
# ===============================
POSITIVE_EMOJIS = ['ğŸ˜Š','ğŸ˜ƒ','ğŸ˜','ğŸ˜','ğŸ¥°','ğŸ‘','ğŸ‘','ğŸ”¥','â¤ï¸','ğŸ†','ğŸ¥‡','ğŸ¯','âœ¨','ğŸ’ª']
NEGATIVE_EMOJIS = ['ğŸ˜¢','ğŸ˜­','ğŸ˜','ğŸ˜¡','ğŸ¤¬','ğŸ’”','ğŸ‘','âŒ','ğŸ˜°','â˜¹ï¸','ğŸ˜©']

@udf(IntegerType())
def count_positive_emojis(text):
    return builtins.sum(1 for e in POSITIVE_EMOJIS if e in text) if text else 0

@udf(IntegerType())
def count_negative_emojis(text):
    return builtins.sum(1 for e in NEGATIVE_EMOJIS if e in text) if text else 0

df = df.withColumn("positive_emojis", count_positive_emojis(col("combined_text")))
df = df.withColumn("negative_emojis", count_negative_emojis(col("combined_text")))
df = df.withColumn("emoji_score", col("positive_emojis") - col("negative_emojis"))

# ===============================
# AUTO-LABELING AMÃ‰LIORÃ‰
# ===============================
@udf(StringType())
def auto_label_improved(text, score, comments, emoji_score):
    """
    Auto-labeling amÃ©liorÃ© avec dÃ©tection des tragÃ©dies
    """
    if not text:
        return "neutral"

    text_lower = text.lower()
    
    # ========================================
    # MOTS-CLÃ‰S POSITIFS (Football/CAN)
    # ========================================
    positive_words = [
        'win', 'won', 'victory', 'champion', 'champions', 'qualify', 'qualified',
        'great', 'amazing', 'excellent', 'brilliant', 'fantastic',
        'love', 'best', 'perfect', 'hero', 'legend', 'historic',
        'celebrate', 'celebration', 'goal', 'goals', 'dominant',
        'unstoppable', 'impressive', 'proud', 'congrat'
    ]
    
    # ========================================
    # MOTS-CLÃ‰S NÃ‰GATIFS (CORRIGÃ‰ !)
    # ========================================
    negative_words = [
        # DÃ©faites sportives
        'lose', 'lost', 'defeat', 'defeated', 'fail', 'failed',
        'exit', 'eliminated', 'elimination', 'disappoint',
        'terrible', 'worst', 'poor', 'awful', 'weak',
        'shame', 'embarrass', 'pathetic', 'useless',
        
        # AJOUT CRUCIAL : TragÃ©dies et Violence
        'kill', 'killed', 'killing', 'death', 'dead', 'die', 'died',
        'war', 'civil war', 'conflict', 'violence', 'violent',
        'shot', 'shoot', 'shooting', 'murdered', 'murder',
        'attack', 'attacked', 'victim', 'victims', 'tragedy', 'tragic',
        'crisis', 'disaster', 'horror', 'horrific', 'terror',
        'threat', 'threaten', 'danger', 'dangerous'
    ]
    
    # Compter les occurrences
    pos_count = builtins.sum(1 for w in positive_words if w in text_lower)
    neg_count = builtins.sum(1 for w in negative_words if w in text_lower)
    
    # Score initial basÃ© sur les mots
    total_score = (pos_count - neg_count) * 3
    
    # Ajouter le score des emojis
    if emoji_score:
        total_score += emoji_score * 2
    
    # ========================================
    # PONDÃ‰RATION SCORE REDDIT (AMÃ‰LIORÃ‰E)
    # ========================================
    # Score Ã©levÃ© ne signifie pas forcÃ©ment positif !
    # Un post tragique peut Ãªtre trÃ¨s upvotÃ© car important
    if score:
        # Seulement si pas de mots nÃ©gatifs forts
        if neg_count == 0:
            if score > 100:
                total_score += 1  # RÃ©duit de 2 â†’ 1
            elif score < -5:
                total_score -= 2
        else:
            # Si mots nÃ©gatifs prÃ©sents, le score ne compte pas
            if score < -5:
                total_score -= 2
    
    # Bonus engagement (si beaucoup de commentaires)
    if comments and comments > 50:
        total_score += 1
    
    # ========================================
    # DÃ‰CISION FINALE
    # ========================================
    if total_score > 2:
        return "positive"
    elif total_score < -2:
        return "negative"
    else:
        return "neutral"

df = df.withColumn(
    "label",
    auto_label_improved(
        col("combined_text"),
        col("score"),
        col("num_comments"),
        col("emoji_score")
    )
)

print("\nğŸ“Š Distribution des labels :")
df.groupBy("label").count().orderBy("count", ascending=False).show()

# ===============================
# CLEAN TEXT
# ===============================
@udf(StringType())
def clean_text(text):
    if not text:
        return ""
    text = text.lower()
    # Supprimer URLs
    text = re.sub(r"http\S+|www\S+|https\S+", "", text)
    # Garder lettres, chiffres, espaces et emojis
    text = re.sub(r"[^\w\sğŸ˜€-ğŸ™]", " ", text)
    # Supprimer espaces multiples
    return re.sub(r"\s+", " ", text).strip()

df = df.withColumn("cleaned_text", clean_text(col("combined_text")))

# ===============================
# PIPELINE FEATURES
# ===============================
label_indexer = StringIndexer(
    inputCol="label",
    outputCol="label_index",
    handleInvalid="keep"
)

tokenizer = Tokenizer(inputCol="cleaned_text", outputCol="words")

remover = StopWordsRemover(inputCol="words", outputCol="filtered_words")

cv = CountVectorizer(
    inputCol="filtered_words",
    outputCol="raw_features",
    vocabSize=2000,
    minDF=2
)

idf = IDF(inputCol="raw_features", outputCol="text_features")

assembler = VectorAssembler(
    inputCols=["text_features", "score", "num_comments", "emoji_score"],
    outputCol="features",
    handleInvalid="skip"
)

# ===============================
# SPLIT
# ===============================
train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)
print(f"\nğŸ“Š Train: {train_df.count()} | Test: {test_df.count()}")

# ===============================
# MODÃˆLE 1: LOGISTIC REGRESSION
# ===============================
print("\nğŸ”„ EntraÃ®nement Logistic Regression...")

lr = LogisticRegression(
    featuresCol="features",
    labelCol="label_index",
    maxIter=100,
    regParam=0.01
)

lr_pipeline = Pipeline(stages=[
    label_indexer, tokenizer, remover, cv, idf, assembler, lr
])

try:
    lr_model = lr_pipeline.fit(train_df)
    lr_preds = lr_model.transform(test_df)
    
    evaluator = MulticlassClassificationEvaluator(
        labelCol="label_index",
        predictionCol="prediction",
        metricName="accuracy"
    )
    
    lr_acc = evaluator.evaluate(lr_preds)
    print(f"âœ… Logistic Regression Accuracy: {lr_acc:.2%}")
except Exception as e:
    print(f"âš ï¸  Logistic Regression: {e}")
    lr_acc = 0
    lr_model = None

# ===============================
# MODÃˆLE 2: RANDOM FOREST (BEST)
# ===============================
print("\nğŸ”„ EntraÃ®nement Random Forest...")

rf = RandomForestClassifier(
    featuresCol="features",
    labelCol="label_index",
    numTrees=50,
    maxDepth=10,
    seed=42
)

rf_pipeline = Pipeline(stages=[
    label_indexer, tokenizer, remover, cv, idf, assembler, rf
])

try:
    rf_model = rf_pipeline.fit(train_df)
    rf_preds = rf_model.transform(test_df)
    
    rf_acc = evaluator.evaluate(rf_preds)
    print(f"âœ… Random Forest Accuracy: {rf_acc:.2%}")
except Exception as e:
    print(f"âš ï¸  Random Forest: {e}")
    rf_acc = 0
    rf_model = None

# ===============================
# MODÃˆLE 3: NAIVE BAYES
# ===============================
print("\nğŸ”„ EntraÃ®nement Naive Bayes...")

nb = NaiveBayes(
    featuresCol="features",
    labelCol="label_index",
    smoothing=1.0
)

nb_pipeline = Pipeline(stages=[
    label_indexer, tokenizer, remover, cv, idf, assembler, nb
])

try:
    nb_model = nb_pipeline.fit(train_df)
    nb_preds = nb_model.transform(test_df)
    
    nb_acc = evaluator.evaluate(nb_preds)
    print(f"âœ… Naive Bayes Accuracy: {nb_acc:.2%}")
except Exception as e:
    print(f"âš ï¸  Naive Bayes: {e}")
    nb_acc = 0
    nb_model = None

# ===============================
# COMPARAISON & SÃ‰LECTION
# ===============================
models = [
    ("Logistic Regression", lr_model, lr_acc),
    ("Random Forest", rf_model, rf_acc),
    ("Naive Bayes", nb_model, nb_acc)
]

# Trier par accuracy
models = [(n, m, a) for n, m, a in models if m is not None]
models.sort(key=lambda x: x[2], reverse=True)

if not models:
    print("âŒ Aucun modÃ¨le n'a pu Ãªtre entraÃ®nÃ©")
    exit(1)

best_name, best_model, best_acc = models[0]

print("\n" + "=" * 70)
print("ğŸ† COMPARAISON DES MODÃˆLES")
print("=" * 70)
for name, model, acc in models:
    status = "ğŸ†" if name == best_name else "  "
    print(f"{status} {name:25s} | Accuracy: {acc:6.2%}")
print("=" * 70)
print(f"\nğŸ¯ MEILLEUR MODÃˆLE : {best_name}")
print(f"   Accuracy: {best_acc:.2%}")
print("=" * 70)

# ===============================
# MAPPING CORRECT DES LABELS
# ===============================
real_labels = best_model.stages[0].labels
print(f"\nğŸ” Ordre rÃ©el des labels Spark : {real_labels}")

index_to_label = IndexToString(
    inputCol="prediction",
    outputCol="predicted_sentiment",
    labels=real_labels
)

final_df = index_to_label.transform(best_model.transform(df))

# ===============================
# RÃ‰SULTATS FINAUX
# ===============================
result_df = final_df.select(
    "id",
    "combined_text",
    col("label").alias("true_sentiment"),
    "predicted_sentiment",
    "score",
    "num_comments",
    "emoji_score",
    "positive_emojis",
    "negative_emojis",
    current_timestamp().alias("analyzed_at")
)

print("\nğŸ“Š Distribution finale des prÃ©dictions :")
result_df.groupBy("predicted_sentiment").count().orderBy("count", ascending=False).show()

print("\nğŸ“‹ Exemples de prÃ©dictions (posts avec tragÃ©dies) :")
tragedy_posts = result_df.filter(
    col("combined_text").contains("kill") | 
    col("combined_text").contains("war") |
    col("combined_text").contains("death")
)

if tragedy_posts.count() > 0:
    print("ğŸ” Posts tragiques dÃ©tectÃ©s :")
    tragedy_posts.select(
        "combined_text",
        "predicted_sentiment",
        "score"
    ).show(5, truncate=60)

# ===============================
# SAVE TO MONGODB
# ===============================
print("\nğŸ’¾ Sauvegarde MongoDB...")
pdf = result_df.toPandas()
pdf["analyzed_at"] = pdf["analyzed_at"].astype(str)

saved_count = 0
for doc in pdf.to_dict("records"):
    try:
        results_col.update_one(
            {"id": doc["id"]},
            {"$set": doc},
            upsert=True
        )
        saved_count += 1
    except Exception as e:
        print(f"âš ï¸  Erreur: {e}")

print(f"âœ… {saved_count}/{len(pdf)} documents sauvegardÃ©s")

# ===============================
# STATISTIQUES FINALES
# ===============================
print("\n" + "=" * 70)
print("ğŸ“Š STATISTIQUES FINALES")
print("=" * 70)
print(f"Total posts analysÃ©s:     {len(pdf)}")
print(f"Accuracy finale:          {best_acc:.2%}")
print(f"ModÃ¨le utilisÃ©:           {best_name}")
print("=" * 70)

# VÃ©rifier la correction
if tragedy_posts.count() > 0:
    neg_count = tragedy_posts.filter(col("predicted_sentiment") == "negative").count()
    total = tragedy_posts.count()
    print(f"\nğŸ” VÃ©rification tragÃ©dies:")
    print(f"   Posts tragiques dÃ©tectÃ©s: {total}")
    print(f"   ClassÃ©s nÃ©gatifs:         {neg_count} ({neg_count/total*100:.1f}%)")
    print("=" * 70)

print("\nâœ… ANALYSE TERMINÃ‰E AVEC SUCCÃˆS")
print("=" * 70)

spark.stop()
mongo.close()